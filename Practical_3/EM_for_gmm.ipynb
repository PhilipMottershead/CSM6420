{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1-final"
    },
    "colab": {
      "name": "EM-for-gmm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzm2nmbUTyQS"
      },
      "source": [
        "# Fitting Gaussian Mixture Models with EM\n",
        "\n",
        "In this tutorial, which was adapted from coursera machine learning course by university of washington, you will\n",
        "* implement the EM algorithm for a Gaussian mixture model\n",
        "* apply your implementation to cluster images\n",
        "* explore clustering results and interpret the output of the EM algorithm  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r9vkc8VTyQd"
      },
      "source": [
        "## Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "scrolled": true,
        "id": "sNrLjgruTyQe"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import copy\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FXznqvFTyQf"
      },
      "source": [
        "## Implementing the EM algorithm for Gaussian mixture models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPKiQxVtTyQf"
      },
      "source": [
        "In this section, you will implement the EM algorithm. We will take the following steps:\n",
        "\n",
        "- Create some synthetic data.\n",
        "- Provide a log likelihood function for this model.\n",
        "- Implement the EM algorithm.\n",
        "- Visualize the progress of the parameters during the course of running EM.\n",
        "- Visualize the convergence of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjboWpS5TyQg"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "To help us develop and test our implementation, we will generate some observations from a mixture of Gaussians and then run our EM algorithm to discover the mixture components. We'll begin with a function to generate the data, and a quick plot to visualize its output for a 2-dimensional mixture of three Gaussians.\n",
        "\n",
        "Now we will create a function to generate data from a mixture of Gaussians model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "qWgyV518TyQg"
      },
      "source": [
        "def generate_MoG_data(num_data, means, covariances, weights):\n",
        "    \"\"\" Creates a list of data points \"\"\"\n",
        "    num_clusters = len(weights)\n",
        "    data = []\n",
        "    for i in range(num_data):\n",
        "        #  Use np.random.choice and weights to pick a cluster id \n",
        "        #  greater than or equal to 0 and less than num_clusters.\n",
        "        k = np.random.choice(len(weights), 1, p=weights)[0]\n",
        "\n",
        "        # Use np.random.multivariate_normal to create data from this cluster\n",
        "        x = np.random.multivariate_normal(means[k], covariances[k])\n",
        "\n",
        "        data.append(x)\n",
        "    return data"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10NuoSSGTyQg"
      },
      "source": [
        "After specifying a particular set of clusters (so that the results are reproducible across assignments), we use the above function to generate a dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RnlPyOtSTyQh"
      },
      "source": [
        "# Model parameters\n",
        "init_means = [\n",
        "    [5, 0], # mean of cluster 1\n",
        "    [1, 1], # mean of cluster 2\n",
        "    [0, 5]  # mean of cluster 3\n",
        "]\n",
        "init_covariances = [\n",
        "    [[.5, 0.], [0, .5]], # covariance of cluster 1\n",
        "    [[.92, .38], [.38, .91]], # covariance of cluster 2\n",
        "    [[.5, 0.], [0, .5]]  # covariance of cluster 3\n",
        "]\n",
        "init_weights = [1/4., 1/2., 1/4.]  # weights of each cluster\n",
        "\n",
        "# Generate data\n",
        "np.random.seed(4)\n",
        "data = generate_MoG_data(100, init_means, init_covariances, init_weights)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgYKPNXrTyQh"
      },
      "source": [
        "Now plot the data you created above. The plot should be a scatterplot with 100 points that appear to roughly fall into three clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpW5eFwLTyQi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "b9b27001-d35f-4032-8fa6-931ce2ae8563"
      },
      "source": [
        "plt.figure()\n",
        "d = np.vstack(data)\n",
        "plt.plot(d[:,0], d[:,1],'ko')\n",
        "plt.rcParams.update({'font.size':16})\n",
        "plt.tight_layout()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"267.518125pt\" version=\"1.1\" viewBox=\"0 0 411.832187 267.518125\" width=\"411.832187pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-02-17T09:55:27.513139</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.4, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 267.518125 \nL 411.832187 267.518125 \nL 411.832187 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 28.942188 243.64 \nL 404.632187 243.64 \nL 404.632187 7.2 \nL 28.942188 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mb818c7856e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.197545\" xlink:href=\"#mb818c7856e\" y=\"243.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(105.016295 258.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"201.108078\" xlink:href=\"#mb818c7856e\" y=\"243.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2 -->\n      <g transform=\"translate(197.926828 258.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"294.018612\" xlink:href=\"#mb818c7856e\" y=\"243.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4 -->\n      <g transform=\"translate(290.837362 258.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"386.929146\" xlink:href=\"#mb818c7856e\" y=\"243.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6 -->\n      <g transform=\"translate(383.747896 258.238438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_5\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m94aae54dbe\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m94aae54dbe\" y=\"241.745793\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- −2 -->\n      <g transform=\"translate(7.2 245.545011)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m94aae54dbe\" y=\"188.506072\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 0 -->\n      <g transform=\"translate(15.579688 192.305291)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m94aae54dbe\" y=\"135.266352\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2 -->\n      <g transform=\"translate(15.579688 139.065571)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m94aae54dbe\" y=\"82.026632\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 4 -->\n      <g transform=\"translate(15.579688 85.825851)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.942188\" xlink:href=\"#m94aae54dbe\" y=\"28.786912\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 6 -->\n      <g transform=\"translate(15.579688 32.58613)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_10\">\n    <defs>\n     <path d=\"M 0 3 \nC 0.795609 3 1.55874 2.683901 2.12132 2.12132 \nC 2.683901 1.55874 3 0.795609 3 0 \nC 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \nC 1.55874 -2.683901 0.795609 -3 0 -3 \nC -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \nC -2.683901 -1.55874 -3 -0.795609 -3 0 \nC -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \nC -1.55874 2.683901 -0.795609 3 0 3 \nz\n\" id=\"m622b3412d5\" style=\"stroke:#000000;\"/>\n    </defs>\n    <g clip-path=\"url(#p11ed4f8335)\">\n     <use style=\"stroke:#000000;\" x=\"122.991395\" xlink:href=\"#m622b3412d5\" y=\"54.559701\"/>\n     <use style=\"stroke:#000000;\" x=\"175.571311\" xlink:href=\"#m622b3412d5\" y=\"131.082356\"/>\n     <use style=\"stroke:#000000;\" x=\"155.881754\" xlink:href=\"#m622b3412d5\" y=\"61.784258\"/>\n     <use style=\"stroke:#000000;\" x=\"351.387905\" xlink:href=\"#m622b3412d5\" y=\"210.105121\"/>\n     <use style=\"stroke:#000000;\" x=\"324.544713\" xlink:href=\"#m622b3412d5\" y=\"190.777372\"/>\n     <use style=\"stroke:#000000;\" x=\"128.520123\" xlink:href=\"#m622b3412d5\" y=\"57.062957\"/>\n     <use style=\"stroke:#000000;\" x=\"102.271537\" xlink:href=\"#m622b3412d5\" y=\"51.601118\"/>\n     <use style=\"stroke:#000000;\" x=\"302.473813\" xlink:href=\"#m622b3412d5\" y=\"181.899224\"/>\n     <use style=\"stroke:#000000;\" x=\"185.149148\" xlink:href=\"#m622b3412d5\" y=\"211.929252\"/>\n     <use style=\"stroke:#000000;\" x=\"75.907415\" xlink:href=\"#m622b3412d5\" y=\"54.38218\"/>\n     <use style=\"stroke:#000000;\" x=\"387.555369\" xlink:href=\"#m622b3412d5\" y=\"138.534561\"/>\n     <use style=\"stroke:#000000;\" x=\"117.534685\" xlink:href=\"#m622b3412d5\" y=\"213.319297\"/>\n     <use style=\"stroke:#000000;\" x=\"90.41994\" xlink:href=\"#m622b3412d5\" y=\"181.487647\"/>\n     <use style=\"stroke:#000000;\" x=\"342.050828\" xlink:href=\"#m622b3412d5\" y=\"232.89229\"/>\n     <use style=\"stroke:#000000;\" x=\"179.687145\" xlink:href=\"#m622b3412d5\" y=\"191.895237\"/>\n     <use style=\"stroke:#000000;\" x=\"146.034717\" xlink:href=\"#m622b3412d5\" y=\"144.970966\"/>\n     <use style=\"stroke:#000000;\" x=\"188.189997\" xlink:href=\"#m622b3412d5\" y=\"180.92987\"/>\n     <use style=\"stroke:#000000;\" x=\"336.180384\" xlink:href=\"#m622b3412d5\" y=\"173.408329\"/>\n     <use style=\"stroke:#000000;\" x=\"136.308586\" xlink:href=\"#m622b3412d5\" y=\"58.71958\"/>\n     <use style=\"stroke:#000000;\" x=\"168.992561\" xlink:href=\"#m622b3412d5\" y=\"204.13487\"/>\n     <use style=\"stroke:#000000;\" x=\"117.289144\" xlink:href=\"#m622b3412d5\" y=\"35.751569\"/>\n     <use style=\"stroke:#000000;\" x=\"292.661273\" xlink:href=\"#m622b3412d5\" y=\"178.036951\"/>\n     <use style=\"stroke:#000000;\" x=\"130.120146\" xlink:href=\"#m622b3412d5\" y=\"149.205227\"/>\n     <use style=\"stroke:#000000;\" x=\"169.59144\" xlink:href=\"#m622b3412d5\" y=\"173.46948\"/>\n     <use style=\"stroke:#000000;\" x=\"289.367724\" xlink:href=\"#m622b3412d5\" y=\"163.900483\"/>\n     <use style=\"stroke:#000000;\" x=\"113.403084\" xlink:href=\"#m622b3412d5\" y=\"17.947273\"/>\n     <use style=\"stroke:#000000;\" x=\"127.112882\" xlink:href=\"#m622b3412d5\" y=\"144.015106\"/>\n     <use style=\"stroke:#000000;\" x=\"134.320053\" xlink:href=\"#m622b3412d5\" y=\"55.04744\"/>\n     <use style=\"stroke:#000000;\" x=\"192.798864\" xlink:href=\"#m622b3412d5\" y=\"167.505073\"/>\n     <use style=\"stroke:#000000;\" x=\"72.15837\" xlink:href=\"#m622b3412d5\" y=\"65.349051\"/>\n     <use style=\"stroke:#000000;\" x=\"129.117498\" xlink:href=\"#m622b3412d5\" y=\"215.41864\"/>\n     <use style=\"stroke:#000000;\" x=\"212.733245\" xlink:href=\"#m622b3412d5\" y=\"171.24764\"/>\n     <use style=\"stroke:#000000;\" x=\"176.560088\" xlink:href=\"#m622b3412d5\" y=\"143.681676\"/>\n     <use style=\"stroke:#000000;\" x=\"106.24181\" xlink:href=\"#m622b3412d5\" y=\"174.950399\"/>\n     <use style=\"stroke:#000000;\" x=\"163.176834\" xlink:href=\"#m622b3412d5\" y=\"173.338548\"/>\n     <use style=\"stroke:#000000;\" x=\"364.724436\" xlink:href=\"#m622b3412d5\" y=\"176.25689\"/>\n     <use style=\"stroke:#000000;\" x=\"140.257307\" xlink:href=\"#m622b3412d5\" y=\"151.215582\"/>\n     <use style=\"stroke:#000000;\" x=\"109.185213\" xlink:href=\"#m622b3412d5\" y=\"61.734713\"/>\n     <use style=\"stroke:#000000;\" x=\"355.593725\" xlink:href=\"#m622b3412d5\" y=\"149.413112\"/>\n     <use style=\"stroke:#000000;\" x=\"228.333398\" xlink:href=\"#m622b3412d5\" y=\"132.086757\"/>\n     <use style=\"stroke:#000000;\" x=\"116.659883\" xlink:href=\"#m622b3412d5\" y=\"70.160107\"/>\n     <use style=\"stroke:#000000;\" x=\"113.696383\" xlink:href=\"#m622b3412d5\" y=\"197.386893\"/>\n     <use style=\"stroke:#000000;\" x=\"138.896826\" xlink:href=\"#m622b3412d5\" y=\"160.85359\"/>\n     <use style=\"stroke:#000000;\" x=\"197.2334\" xlink:href=\"#m622b3412d5\" y=\"171.538738\"/>\n     <use style=\"stroke:#000000;\" x=\"121.431585\" xlink:href=\"#m622b3412d5\" y=\"66.945507\"/>\n     <use style=\"stroke:#000000;\" x=\"130.331138\" xlink:href=\"#m622b3412d5\" y=\"36.085724\"/>\n     <use style=\"stroke:#000000;\" x=\"252.419447\" xlink:href=\"#m622b3412d5\" y=\"129.943066\"/>\n     <use style=\"stroke:#000000;\" x=\"68.535847\" xlink:href=\"#m622b3412d5\" y=\"77.397597\"/>\n     <use style=\"stroke:#000000;\" x=\"112.165788\" xlink:href=\"#m622b3412d5\" y=\"71.70302\"/>\n     <use style=\"stroke:#000000;\" x=\"118.147523\" xlink:href=\"#m622b3412d5\" y=\"39.399869\"/>\n     <use style=\"stroke:#000000;\" x=\"94.292338\" xlink:href=\"#m622b3412d5\" y=\"65.369339\"/>\n     <use style=\"stroke:#000000;\" x=\"213.110217\" xlink:href=\"#m622b3412d5\" y=\"159.043009\"/>\n     <use style=\"stroke:#000000;\" x=\"329.9556\" xlink:href=\"#m622b3412d5\" y=\"190.10392\"/>\n     <use style=\"stroke:#000000;\" x=\"142.153299\" xlink:href=\"#m622b3412d5\" y=\"151.179683\"/>\n     <use style=\"stroke:#000000;\" x=\"126.431463\" xlink:href=\"#m622b3412d5\" y=\"173.297198\"/>\n     <use style=\"stroke:#000000;\" x=\"149.771283\" xlink:href=\"#m622b3412d5\" y=\"137.127645\"/>\n     <use style=\"stroke:#000000;\" x=\"96.227416\" xlink:href=\"#m622b3412d5\" y=\"78.871747\"/>\n     <use style=\"stroke:#000000;\" x=\"133.767809\" xlink:href=\"#m622b3412d5\" y=\"182.712818\"/>\n     <use style=\"stroke:#000000;\" x=\"92.173385\" xlink:href=\"#m622b3412d5\" y=\"66.827018\"/>\n     <use style=\"stroke:#000000;\" x=\"327.295688\" xlink:href=\"#m622b3412d5\" y=\"171.657448\"/>\n     <use style=\"stroke:#000000;\" x=\"186.158798\" xlink:href=\"#m622b3412d5\" y=\"154.13666\"/>\n     <use style=\"stroke:#000000;\" x=\"177.240148\" xlink:href=\"#m622b3412d5\" y=\"190.55346\"/>\n     <use style=\"stroke:#000000;\" x=\"362.133706\" xlink:href=\"#m622b3412d5\" y=\"188.190825\"/>\n     <use style=\"stroke:#000000;\" x=\"46.019006\" xlink:href=\"#m622b3412d5\" y=\"193.842703\"/>\n     <use style=\"stroke:#000000;\" x=\"108.875074\" xlink:href=\"#m622b3412d5\" y=\"40.270943\"/>\n     <use style=\"stroke:#000000;\" x=\"177.697001\" xlink:href=\"#m622b3412d5\" y=\"59.948004\"/>\n     <use style=\"stroke:#000000;\" x=\"375.762775\" xlink:href=\"#m622b3412d5\" y=\"191.984309\"/>\n     <use style=\"stroke:#000000;\" x=\"187.348303\" xlink:href=\"#m622b3412d5\" y=\"153.533931\"/>\n     <use style=\"stroke:#000000;\" x=\"329.477241\" xlink:href=\"#m622b3412d5\" y=\"197.382345\"/>\n     <use style=\"stroke:#000000;\" x=\"149.75212\" xlink:href=\"#m622b3412d5\" y=\"218.596162\"/>\n     <use style=\"stroke:#000000;\" x=\"183.12052\" xlink:href=\"#m622b3412d5\" y=\"170.725894\"/>\n     <use style=\"stroke:#000000;\" x=\"98.893234\" xlink:href=\"#m622b3412d5\" y=\"54.475471\"/>\n     <use style=\"stroke:#000000;\" x=\"71.429272\" xlink:href=\"#m622b3412d5\" y=\"62.752891\"/>\n     <use style=\"stroke:#000000;\" x=\"170.139979\" xlink:href=\"#m622b3412d5\" y=\"150.49427\"/>\n     <use style=\"stroke:#000000;\" x=\"192.535058\" xlink:href=\"#m622b3412d5\" y=\"125.402957\"/>\n     <use style=\"stroke:#000000;\" x=\"155.997236\" xlink:href=\"#m622b3412d5\" y=\"102.986471\"/>\n     <use style=\"stroke:#000000;\" x=\"99.305073\" xlink:href=\"#m622b3412d5\" y=\"81.222602\"/>\n     <use style=\"stroke:#000000;\" x=\"175.831408\" xlink:href=\"#m622b3412d5\" y=\"165.791575\"/>\n     <use style=\"stroke:#000000;\" x=\"212.073121\" xlink:href=\"#m622b3412d5\" y=\"165.157767\"/>\n     <use style=\"stroke:#000000;\" x=\"123.346015\" xlink:href=\"#m622b3412d5\" y=\"186.046201\"/>\n     <use style=\"stroke:#000000;\" x=\"99.470174\" xlink:href=\"#m622b3412d5\" y=\"32.753378\"/>\n     <use style=\"stroke:#000000;\" x=\"307.923535\" xlink:href=\"#m622b3412d5\" y=\"152.455132\"/>\n     <use style=\"stroke:#000000;\" x=\"131.355176\" xlink:href=\"#m622b3412d5\" y=\"170.286275\"/>\n     <use style=\"stroke:#000000;\" x=\"69.470214\" xlink:href=\"#m622b3412d5\" y=\"33.646232\"/>\n     <use style=\"stroke:#000000;\" x=\"81.348681\" xlink:href=\"#m622b3412d5\" y=\"232.892727\"/>\n     <use style=\"stroke:#000000;\" x=\"193.346794\" xlink:href=\"#m622b3412d5\" y=\"167.306476\"/>\n     <use style=\"stroke:#000000;\" x=\"155.45965\" xlink:href=\"#m622b3412d5\" y=\"165.996476\"/>\n     <use style=\"stroke:#000000;\" x=\"130.725127\" xlink:href=\"#m622b3412d5\" y=\"176.347205\"/>\n     <use style=\"stroke:#000000;\" x=\"86.052708\" xlink:href=\"#m622b3412d5\" y=\"84.278095\"/>\n     <use style=\"stroke:#000000;\" x=\"153.024235\" xlink:href=\"#m622b3412d5\" y=\"171.026627\"/>\n     <use style=\"stroke:#000000;\" x=\"156.975181\" xlink:href=\"#m622b3412d5\" y=\"178.297263\"/>\n     <use style=\"stroke:#000000;\" x=\"162.7634\" xlink:href=\"#m622b3412d5\" y=\"169.055942\"/>\n     <use style=\"stroke:#000000;\" x=\"110.352305\" xlink:href=\"#m622b3412d5\" y=\"59.081126\"/>\n     <use style=\"stroke:#000000;\" x=\"185.658208\" xlink:href=\"#m622b3412d5\" y=\"147.463256\"/>\n     <use style=\"stroke:#000000;\" x=\"152.03849\" xlink:href=\"#m622b3412d5\" y=\"153.336699\"/>\n     <use style=\"stroke:#000000;\" x=\"369.983597\" xlink:href=\"#m622b3412d5\" y=\"188.875687\"/>\n     <use style=\"stroke:#000000;\" x=\"132.679321\" xlink:href=\"#m622b3412d5\" y=\"45.477101\"/>\n     <use style=\"stroke:#000000;\" x=\"331.381021\" xlink:href=\"#m622b3412d5\" y=\"167.163645\"/>\n     <use style=\"stroke:#000000;\" x=\"108.048172\" xlink:href=\"#m622b3412d5\" y=\"182.959316\"/>\n     <use style=\"stroke:#000000;\" x=\"172.74675\" xlink:href=\"#m622b3412d5\" y=\"163.211736\"/>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 28.942188 243.64 \nL 28.942188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 404.632187 243.64 \nL 404.632187 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 28.942188 243.64 \nL 404.632188 243.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 28.942188 7.2 \nL 404.632188 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p11ed4f8335\">\n   <rect height=\"236.44\" width=\"375.69\" x=\"28.942188\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpglMmHpTyQk"
      },
      "source": [
        "### Log likelihood \n",
        "We provide a function to calculate log likelihood for mixture of Gaussians. The log likelihood quantifies the probability of observing a given set of data under a particular setting of the parameters in our model. We will use this to assess convergence of our EM algorithm; specifically, we will keep looping through EM update steps until the log likehood ceases to increase at a certain rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "Bwn3F0PpTyQk"
      },
      "source": [
        "def log_sum_exp(Z):\n",
        "    \"\"\" Compute log(\\sum_i exp(Z_i)) for some array Z.\"\"\"\n",
        "    return np.max(Z) + np.log(np.sum(np.exp(Z - np.max(Z))))\n",
        "\n",
        "def loglikelihood(data, weights, means, covs):\n",
        "    \"\"\" Compute the loglikelihood of the data for a Gaussian mixture model with the given parameters. \"\"\"\n",
        "    num_clusters = len(means)\n",
        "    num_dim = len(data[0])\n",
        "    \n",
        "    ll = 0\n",
        "    for d in data:\n",
        "        \n",
        "        Z = np.zeros(num_clusters)\n",
        "        for k in range(num_clusters):\n",
        "            \n",
        "            # Compute (x-mu)^T * Sigma^{-1} * (x-mu)\n",
        "            delta = np.array(d) - means[k]\n",
        "            exponent_term = np.dot(delta.T, np.dot(np.linalg.inv(covs[k]), delta))\n",
        "            \n",
        "            # Compute loglikelihood contribution for this data point and this cluster\n",
        "            Z[k] += np.log(weights[k])\n",
        "            Z[k] -= 1/2. * (num_dim * np.log(2*np.pi) + np.log(np.linalg.det(covs[k])) + exponent_term)\n",
        "            \n",
        "        # Increment loglikelihood contribution of this data point across all clusters\n",
        "        ll += log_sum_exp(Z)\n",
        "        \n",
        "    return ll"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61ledXXBWxZ2"
      },
      "source": [
        "### E-step: assign cluster responsibilities, given current parameters\n",
        "\n",
        "The first step in the EM algorithm is to compute cluster responsibilities. Let $r_{ik}$ denote the responsibility of cluster $k$ for data point $i$. Note that cluster responsibilities are fractional parts: Cluster responsibilities for a single data point $i$ should sum to 1.\n",
        "$$\n",
        "r_{i1} + r_{i2} + \\ldots + r_{iK} = 1\n",
        "$$\n",
        "\n",
        "To figure how much a cluster is responsible for a given data point, we compute the likelihood of the data point under the  particular cluster assignment, multiplied by the weight of the cluster. For data point $i$ and cluster $k$, this quantity is\n",
        "$$\n",
        "r_{ik} \\propto \\pi_k N(x_i | \\mu_k, \\Sigma_k)\n",
        "$$\n",
        "where $N(x_i | \\mu_k, \\Sigma_k)$ is the Gaussian distribution for cluster $k$ (with mean $\\mu_k$ and covariance $\\Sigma_k$).\n",
        "\n",
        "We used $\\propto$ because the quantity $N(x_i | \\mu_k, \\Sigma_k)$ is not yet the responsibility we want. To ensure that all responsibilities over each data point add up to 1, we add the normalization constant in the denominator:\n",
        "$$\n",
        "r_{ik} = \\frac{\\pi_k N(x_i | \\mu_k, \\Sigma_k)}{\\sum_{k=1}^{K} \\pi_k N(x_i | \\mu_k, \\Sigma_k)}.\n",
        "$$\n",
        "\n",
        "Complete the following function that computes $r_{ik}$ for all data points $i$ and clusters $k$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ujAXKRpYL8"
      },
      "source": [
        "Drawing from a Gaussian distribution. SciPy provides a convenient function [multivariate_normal.pdf](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html) that computes the likelihood of seeing a data point in a multivariate Gaussian distribution. The usage is\n",
        "\n",
        "multivariate_normal.pdf([data point], mean=[mean vector], cov=[covariance matrix])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rTiN_4Cj3Jf"
      },
      "source": [
        "def compute_responsibilities(data, weights, means, covariances):\n",
        "    '''E-step: compute responsibilities, given the current parameters'''\n",
        "    num_data = len(data)\n",
        "    num_clusters = len(means)\n",
        "    resp = np.zeros((num_data, num_clusters))\n",
        "    \n",
        "    # Update resp matrix so that resp[i,k] is the responsibility of cluster k for data point i.\n",
        "    # Hint: To compute likelihood of seeing data point i given cluster k, use multivariate_normal.pdf.\n",
        "    for i in range(num_data):\n",
        "        for k in range(num_clusters):\n",
        "            # YOUR CODE HERE\n",
        "            resp[i, k] = ...\n",
        "\n",
        "    # Add up responsibilities over each data point and normalize\n",
        "    row_sums = resp.sum(axis=1)[:, np.newaxis]\n",
        "    resp = resp / row_sums\n",
        "\n",
        "    return resp"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuqYV15Vkh_w"
      },
      "source": [
        "#### Check point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "191jtn6fkZ2d"
      },
      "source": [
        "resp = compute_responsibilities(data=np.array([[1.,2.],[-1.,-2.]]), weights=np.array([0.3, 0.7]),\n",
        "                                means=[np.array([0.,0.]), np.array([1.,1.])],\n",
        "                                covariances=[np.array([[1.5, 0.],[0.,2.5]]), np.array([[1.,1.],[1.,2.]])])\n",
        "\n",
        "if resp.shape==(2,2) and np.allclose(resp, np.array([[0.10512733, 0.89487267], [0.46468164, 0.53531836]])):\n",
        "    print('Checkpoint passed!')\n",
        "else:\n",
        "    print('Check your code again.')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "float() argument must be a string or a number, not 'ellipsis'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6a14bd9fd1d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m resp = compute_responsibilities(data=np.array([[1.,2.],[-1.,-2.]]), weights=np.array([0.3, 0.7]),\n\u001b[0m\u001b[1;32m      2\u001b[0m                                 \u001b[0mmeans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 covariances=[np.array([[1.5, 0.],[0.,2.5]]), np.array([[1.,1.],[1.,2.]])])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.10512733\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.89487267\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.46468164\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.53531836\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f7ffd1194f4a>\u001b[0m in \u001b[0;36mcompute_responsibilities\u001b[0;34m(data, weights, means, covariances)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Add up responsibilities over each data point and normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'ellipsis'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cnU_c82W6UF"
      },
      "source": [
        "### M-step: Update parameters, given current cluster responsibilities\n",
        "Once the cluster responsibilities are computed, we update the parameters (weights, means, and covariances) associated with the clusters.\n",
        "\n",
        "**Computing soft counts**. Before updating the parameters, we first compute what is known as \"soft counts\". The soft count of a cluster is the sum of all cluster responsibilities for that cluster:\n",
        "$$\n",
        "N^{\\text{soft}}_k = r_{1k} + r_{2k} + \\ldots + r_{Nk} = \\sum_{i=1}^{N} r_{ik}\n",
        "$$\n",
        "\n",
        "where we loop over data points. Note that, unlike k-means, we must loop over every single data point in the dataset. This is because all clusters are represented in all data points, to a varying degree.\n",
        "\n",
        "We provide the function for computing the soft counts:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4ZPET8ggaMw"
      },
      "source": [
        "def compute_soft_counts(resp):\n",
        "    # Compute the total responsibility assigned to each cluster, which will be useful when \n",
        "    # implementing M-steps below. In the lectures this is called N^{soft}\n",
        "    counts = np.sum(resp, axis=0)\n",
        "    return counts"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KnYWYdMXS9O"
      },
      "source": [
        "**Updating weights.** The cluster weights show us how much each cluster is represented over all data points. The weight of cluster $k$ is given by the ratio of the soft count $N^{\\text{soft}}_{k}$ to the total number of data points $N$:\n",
        "$$\n",
        "\\hat{\\pi}_k = \\frac{N^{\\text{soft}}_{k}}{N}\n",
        "$$\n",
        "Notice that $N$ is equal to the sum over the soft counts $N^{\\text{soft}}_{k}$ of all clusters.\n",
        "\n",
        "Complete the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4lPCyKLg3cL"
      },
      "source": [
        "def compute_weights(counts):\n",
        "    num_clusters = len(counts)\n",
        "    weights = [0.] * num_clusters\n",
        "    \n",
        "    for k in range(num_clusters):\n",
        "        # Update the weight for cluster k using the M-step update rule for the cluster weight, \\hat{\\pi}_k.\n",
        "        # HINT: compute # of data points by summing soft counts.\n",
        "        # YOUR CODE HERE\n",
        "        weights[k] = ...\n",
        "\n",
        "    return weights"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjRel0YXk12L"
      },
      "source": [
        "#### Check point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zGeZ2sYk2RE",
        "outputId": "17ed73f9-99e0-450c-e893-e142c1e950b1"
      },
      "source": [
        "resp = compute_responsibilities(data=np.array([[1.,2.],[-1.,-2.],[0,0]]), weights=np.array([0.3, 0.7]),\n",
        "                                means=[np.array([0.,0.]), np.array([1.,1.])],\n",
        "                                covariances=[np.array([[1.5, 0.],[0.,2.5]]), np.array([[1.,1.],[1.,2.]])])\n",
        "counts = compute_soft_counts(resp)\n",
        "weights = compute_weights(counts)\n",
        "\n",
        "print(counts)\n",
        "print(weights)\n",
        "\n",
        "if np.allclose(weights, [0.27904865942515705, 0.720951340574843]):\n",
        "    print('Checkpoint passed!')\n",
        "else:\n",
        "    print('Check your code again.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.83714598 2.16285402]\n",
            "[array([0.27904866, 0.72095134]), array([0.27904866, 0.72095134])]\n",
            "Checkpoint passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-uWzpBMbCIL"
      },
      "source": [
        "**Updating means**. The mean of each cluster is set to the [weighted average](https://en.wikipedia.org/wiki/Weighted_arithmetic_mean) of all data points, weighted by the cluster responsibilities:\n",
        "$$\n",
        "\\hat{\\mu}_k = \\frac{1}{N_k^{\\text{soft}}} \\sum_{i=1}^N r_{ik}x_i\n",
        "$$\n",
        "\n",
        "Complete the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uHT42Byg6xq"
      },
      "source": [
        "def compute_means(data, resp, counts):\n",
        "    num_clusters = len(counts)\n",
        "    num_data = len(data)\n",
        "    means = [np.zeros(len(data[0]))] * num_clusters\n",
        "    \n",
        "    for k in range(num_clusters):\n",
        "        # Update means for cluster k using the M-step update rule for the mean variables.\n",
        "        # This will assign the variable means[k] to be our estimate for \\hat{\\mu}_k.\n",
        "        weighted_sum = 0.\n",
        "        for i in range(num_data):\n",
        "            # YOUR CODE HERE\n",
        "            weighted_sum += ...\n",
        "        # YOUR CODE HERE\n",
        "        means[k] = ...\n",
        "\n",
        "    return means"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyZ6d38plDEV"
      },
      "source": [
        "#### CHeck point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZERaDoplFEH",
        "outputId": "6003467c-a774-4021-c08d-bbc0ae1bb44e"
      },
      "source": [
        "data_tmp = np.array([[1.,2.],[-1.,-2.]])\n",
        "resp = compute_responsibilities(data=data_tmp, weights=np.array([0.3, 0.7]),\n",
        "                                means=[np.array([0.,0.]), np.array([1.,1.])],\n",
        "                                covariances=[np.array([[1.5, 0.],[0.,2.5]]), np.array([[1.,1.],[1.,2.]])])\n",
        "counts = compute_soft_counts(resp)\n",
        "means = compute_means(data_tmp, resp, counts)\n",
        "\n",
        "if np.allclose(means, np.array([[-0.6310085, -1.262017], [0.25140299, 0.50280599]])):\n",
        "    print('Checkpoint passed!')\n",
        "else:\n",
        "    print('Check your code again.')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRs0VnZohL1w"
      },
      "source": [
        "**Updating covariances**.  The covariance of each cluster is set to the weighted average of all [outer products](https://people.duke.edu/~ccc14/sta-663/LinearAlgebraReview.html), weighted by the cluster responsibilities:\n",
        "$$\n",
        "\\hat{\\Sigma}_k = \\frac{1}{N^{\\text{soft}}_k}\\sum_{i=1}^N r_{ik} (x_i - \\hat{\\mu}_k)(x_i - \\hat{\\mu}_k)^T\n",
        "$$\n",
        "\n",
        "The \"outer product\" in this context refers to the matrix product\n",
        "$$\n",
        "(x_i - \\hat{\\mu}_k)(x_i - \\hat{\\mu}_k)^T.\n",
        "$$\n",
        "Letting $(x_i - \\hat{\\mu}_k)$ to be $d \\times 1$ column vector, this product is a $d \\times d$ matrix. Taking the weighted average of all outer products gives us the covariance matrix, which is also $d \\times d$.\n",
        "\n",
        "Complete the following function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7CzmP2Bi2xv"
      },
      "source": [
        "def compute_covariances(data, resp, counts, means):\n",
        "    num_clusters = len(counts)\n",
        "    num_dim = len(data[0])\n",
        "    num_data = len(data)\n",
        "    covariances = [np.zeros((num_dim,num_dim))] * num_clusters\n",
        "    \n",
        "    for k in range(num_clusters):\n",
        "        # Update covariances for cluster k using the M-step update rule for covariance variables.\n",
        "        # This will assign the variable covariances[k] to be the estimate for \\hat{\\Sigma}_k.\n",
        "        weighted_sum = np.zeros((num_dim, num_dim))\n",
        "        for i in range(num_data):\n",
        "            # YOUR CODE HERE (Hint: Use np.outer on the data[i] and this cluster's mean)\n",
        "            weighted_sum += ...\n",
        "        # YOUR CODE HERE\n",
        "        covariances[k] = ...\n",
        "\n",
        "    return covariances"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xztRBKKslcp2"
      },
      "source": [
        "#### Check point"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsm04BQBlbXT",
        "outputId": "fea16b23-28e8-4ea5-a60f-46af531f0cd6"
      },
      "source": [
        "data_tmp = np.array([[1.,2.],[-1.,-2.]])\n",
        "resp = compute_responsibilities(data=data_tmp, weights=np.array([0.3, 0.7]),\n",
        "                                means=[np.array([0.,0.]), np.array([1.,1.])],\n",
        "                                covariances=[np.array([[1.5, 0.],[0.,2.5]]), np.array([[1.,1.],[1.,2.]])])\n",
        "counts = compute_soft_counts(resp)\n",
        "means = compute_means(data_tmp, resp, counts)\n",
        "covariances = compute_covariances(data_tmp, resp, counts, means)\n",
        "\n",
        "if np.allclose(covariances[0], np.array([[0.60182827, 1.20365655], [1.20365655, 2.4073131]])) and \\\n",
        "    np.allclose(covariances[1], np.array([[ 0.93679654, 1.87359307], [1.87359307, 3.74718614]])):\n",
        "    print('Checkpoint passed!')\n",
        "else:\n",
        "    print('Check your code again.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checkpoint passed!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGCq_bzKTyQl"
      },
      "source": [
        "### Implementation\n",
        "\n",
        "You will now complete an implementation that can run EM on the data you just created. It uses the `loglikelihood` function we provided above.\n",
        "\n",
        "Fill in the places where you find ## YOUR CODE HERE. There are seven places in this function for you to fill in.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6slcNKiemdrF"
      },
      "source": [
        "## The EM algorithm\n",
        "We are almost done. Let us write a function that takes initial parameter estimates and runs EM. You should complete each line that says # YOUR CODE HERE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_UuZ4dPhTyQl"
      },
      "source": [
        "def EM(data, init_means, init_covariances, init_weights, maxiter=1000, thresh=1e-4):\n",
        "    \n",
        "    # Make copies of initial parameters, which we will update during each iteration\n",
        "    means = init_means[:]\n",
        "    covariances = init_covariances[:]\n",
        "    weights = init_weights[:]\n",
        "    \n",
        "    # Infer dimensions of dataset and the number of clusters\n",
        "    num_data = len(data)\n",
        "    num_dim = len(data[0])\n",
        "    num_clusters = len(means)\n",
        "    \n",
        "    # Initialize some useful variables\n",
        "    resp = np.zeros((num_data, num_clusters))\n",
        "    ll = loglikelihood(data, weights, means, covariances)\n",
        "    ll_trace = [ll]\n",
        "    \n",
        "    for i in range(maxiter):\n",
        "        if i % 5 == 0:\n",
        "            print(\"Iteration %s\" % i)\n",
        "        \n",
        "        # E-step: compute responsibilities\n",
        "        # Update resp matrix so that resp[j, k] is the responsibility of cluster k for data point j.\n",
        "        # Hint: To compute likelihood of seeing data point j given cluster k, use multivariate_normal.pdf.\n",
        "        for j in range(num_data):\n",
        "            for k in range(num_clusters):\n",
        "                # YOUR CODE HERE\n",
        "                resp[j, k] = ...\n",
        "        row_sums = resp.sum(axis=1)[:, np.newaxis]\n",
        "        resp = resp / row_sums # normalize over all possible cluster assignments\n",
        "\n",
        "        # M-step\n",
        "        # Compute the total responsibility assigned to each cluster, which will be useful when \n",
        "        # implementing M-steps below. In the lectures this is called N^{soft}\n",
        "        counts = np.sum(resp, axis=0)\n",
        "        \n",
        "        for k in range(num_clusters):\n",
        "            \n",
        "            # Update the weight for cluster k using the M-step update rule for the cluster weight, \\hat{\\pi}_k.\n",
        "            # YOUR CODE HERE\n",
        "            weights[k] = ...\n",
        "            \n",
        "            # Update means for cluster k using the M-step update rule for the mean variables.\n",
        "            # This will assign the variable means[k] to be our estimate for \\hat{\\mu}_k.\n",
        "            weighted_sum = 0\n",
        "            for j in range(num_data):\n",
        "                # YOUR CODE HERE\n",
        "                weighted_sum += ...\n",
        "            # YOUR CODE HERE\n",
        "            means[k] = ...\n",
        "            \n",
        "            # Update covariances for cluster k using the M-step update rule for covariance variables.\n",
        "            # This will assign the variable covariances[k] to be the estimate for \\hat{\\Sigma}_k.\n",
        "            weighted_sum = np.zeros((num_dim, num_dim))\n",
        "            for j in range(num_data):\n",
        "                # YOUR CODE HERE (Hint: Use np.outer on the data[j] and this cluster's mean)\n",
        "                weighted_sum += ...\n",
        "            # YOUR CODE HERE\n",
        "            covariances[k] = ...\n",
        "          \n",
        "        \n",
        "        # Compute the loglikelihood at this iteration\n",
        "        # YOUR CODE HERE\n",
        "        ll_latest = ...\n",
        "        ll_trace.append(ll_latest)\n",
        "        \n",
        "        # Check for convergence in log-likelihood and store\n",
        "        if (ll_latest - ll) < thresh and ll_latest > -np.inf:\n",
        "            break\n",
        "        ll = ll_latest\n",
        "    \n",
        "    if i % 5 != 0:\n",
        "        print(\"Iteration %s\" % i)\n",
        "    \n",
        "    out = {'weights': weights, 'means': means, 'covs': covariances, 'loglik': ll_trace, 'resp': resp}\n",
        "\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlPCJ8y_TyQp"
      },
      "source": [
        "### Testing the implementation on the simulated data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4gvdFUATyQs"
      },
      "source": [
        "Now we'll fit a mixture of Gaussians to this data using our implementation of the EM algorithm. As with k-means, it is important to ask how we obtain an initial configuration of mixing weights and component parameters. In this simple case, we'll take three random points to be the initial cluster means, use the empirical covariance of the data to be the initial covariance in each cluster (a clear overestimate), and set the initial mixing weights to be uniform across clusters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "NLz5cHvbTyQs"
      },
      "source": [
        "np.random.seed(4)\n",
        "\n",
        "# Initialization of parameters\n",
        "chosen = np.random.choice(len(data), 3, replace=False)\n",
        "initial_means = [data[x] for x in chosen]\n",
        "initial_covs = [np.cov(data, rowvar=0)] * 3\n",
        "initial_weights = [1/3.] * 3\n",
        "\n",
        "# Run EM \n",
        "results = EM(data, initial_means, initial_covs, initial_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOCa8v6TTyQt"
      },
      "source": [
        "**Note**. Like k-means, EM is prone to converging to a local optimum. In practice, you may want to run EM multiple times with different random initialization. We have omitted multiple restarts to keep the assignment reasonably short. For the purpose of this assignment, we assign a particular random seed (`seed=4`) to ensure consistent results among the students.\n",
        "\n",
        "**Checkpoint**. For this particular example, the EM algorithm is expected to terminate in 23 iterations. That is, the last line of the log should say \"Iteration 22\". If your function stopped too early or too late, you should re-visit your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vkqGq-TyQw"
      },
      "source": [
        "Our algorithm returns a dictionary with five elements: \n",
        "* 'loglik': a record of the log likelihood at each iteration\n",
        "* 'resp': the final responsibility matrix\n",
        "* 'means': a list of K means\n",
        "* 'covs': a list of K covariance matrices\n",
        "* 'weights': the weights corresponding to each model component"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvN88XhaTyQw"
      },
      "source": [
        "**Quiz Question**: What is the weight that EM assigns to the first component after running the above codeblock?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "N8dUN13fTyQw"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZk9C2qDTyQx"
      },
      "source": [
        "**Quiz Question**: Using the same set of results, obtain the mean that EM assigns the second component. What is the mean in the first dimension?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "8KjV1Sb0TyQx"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_vIT5PSTyQx"
      },
      "source": [
        "**Quiz Question**: Using the same set of results, obtain the covariance that EM assigns the third component. What is the variance in the first dimension?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "JOuFytlWTyQx"
      },
      "source": [
        "# Your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-uxvL3DTyQy"
      },
      "source": [
        "### Plot progress of parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmWyCvbtTyQy"
      },
      "source": [
        "One useful feature of testing our implementation on low-dimensional simulated data is that we can easily visualize the results. \n",
        "\n",
        "We will use the following `plot_contours` function to visualize the Gaussian components over the data at three different points in the algorithm's execution:\n",
        "\n",
        "1. At initialization (using initial_mu, initial_cov, and initial_weights)\n",
        "2. After running the algorithm to completion \n",
        "3. After just 12 iterations (using parameters estimates returned when setting `maxiter=12`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "frBvrVzpTyQy"
      },
      "source": [
        "import matplotlib.mlab as mlab\n",
        "def plot_contours(data, means, covs, title):\n",
        "    plt.figure()\n",
        "    plt.plot([x[0] for x in data], [y[1] for y in data],'ko') # data\n",
        "\n",
        "    delta = 0.025\n",
        "    k = len(means)\n",
        "    x = np.arange(-2.0, 7.0, delta)\n",
        "    y = np.arange(-2.0, 7.0, delta)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    col = ['green', 'red', 'indigo']\n",
        "    for i in range(k):\n",
        "        mean = means[i]\n",
        "        cov = covs[i]\n",
        "        sigmax = np.sqrt(cov[0][0])\n",
        "        sigmay = np.sqrt(cov[1][1])\n",
        "        sigmaxy = cov[0][1]/(sigmax*sigmay)\n",
        "        Z = mlab.bivariate_normal(X, Y, sigmax, sigmay, mean[0], mean[1], sigmaxy)\n",
        "        plt.contour(X, Y, Z, colors = col[i])\n",
        "        plt.title(title)\n",
        "    plt.rcParams.update({'font.size':16})\n",
        "    plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AESzOcGTTyQy"
      },
      "source": [
        "# Parameters after initialization\n",
        "plot_contours(data, initial_means, initial_covs, 'Initial clusters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "mATtZDSKTyQz"
      },
      "source": [
        "# Parameters after running EM to convergence\n",
        "results = EM(data, initial_means, initial_covs, initial_weights)\n",
        "plot_contours(data, results['means'], results['covs'], 'Final clusters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSxVa-FKTyQz"
      },
      "source": [
        "Fill in the following code block to visualize the set of parameters we get after running EM for 12 iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "lVBBeiy2TyQz"
      },
      "source": [
        "# YOUR CODE HERE\n",
        "results = ...\n",
        "\n",
        "plot_contours(data, results['means'], results['covs'], 'Clusters after 12 iterations')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pi48ez8fTyQz"
      },
      "source": [
        "**Quiz Question**: Plot the loglikelihood that is observed at each iteration. Is the loglikelihood plot monotonically increasing, monotonically decreasing, or neither [multiple choice]? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "zjMYBVycTyQz"
      },
      "source": [
        "results = EM(data, initial_means, initial_covs, initial_weights)\n",
        "\n",
        "# YOUR CODE HERE\n",
        "loglikelihoods = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "6kdhszHRTyQ0"
      },
      "source": [
        "plt.plot(range(len(loglikelihoods)), loglikelihoods, linewidth=4)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Log-likelihood')\n",
        "plt.rcParams.update({'font.size':16})\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "jhjOswzWTyQ0"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odkeexBG1Zsq"
      },
      "source": [
        "#### Solutions: [EM_for_gmm_sol.ipynb](https://colab.research.google.com/drive/1W_Ais-YYwAZPNv3JKy2nCW7nSQQmAAbI?usp=sharing)"
      ]
    }
  ]
}