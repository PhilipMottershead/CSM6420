{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Practical6 - CNNs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhilipMottershead/CSM6420/blob/master/prac_6/Practical6_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JAcwxYQ-W6w5"
      },
      "source": [
        "# Convolutional Neural Networks\n",
        "\n",
        "Standard CNNs are comprised of three types of layers: convolutional layers, pooling layers and fully-connected layers.  When  these  layers  are  stacked, a CNN architecture has been formed. A simplified CNN architecture for MNIST image classification is illustrated in Figure 2.\n",
        "\n",
        "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://commons.wikimedia.org/wiki/File:Typical_cnn.png\"><img width=\"718\" alt=\"Typical cnn\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/512px-Typical_cnn.png\"></a>\n",
        "\n",
        "**Figure:** A common form of CNN architecture in which convolutional layers are stacked continuously before being passed through the pooling layer for subsampling, output of which are the features that will be fed to the fully connected (or dense) layers for final output.\n",
        "\n",
        "It is important to note that simply understanding the overall architecture of a CNN architecture will not suffice. The creation and optimisation of these models can take quite some time, and can be quite confusing. We will now explore in detail the individual layers, detailing their hyperparameters and connectivities.\n",
        "\n",
        "As we glide through the input, the scalar product is calculated for each value in that kernel (Figure 3). From this the network will learn kernels that 'fire' when they see a specific feature at a given spatial position of the input. These  are commonly known as **activations**.\n",
        "\n",
        "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://d2l.ai/_images/correlation.svg\"><img width=\"500\" alt=\"Typical cnn\" src=\"https://d2l.ai/_images/correlation.svg\"></a>\n",
        "\n",
        "**Figure 1:** Illustration of a signle step in convolutional operation. The shaded portions are the first output element as well as the input and kernel tensor elements used for the output computation:  0×0+1×1+3×2+4×3=19. \n",
        "\n",
        "Every kernel will have a corresponding activation/feature map, of which will be stacked along the depth dimension to form the full output volume from the convolutional layer.\n",
        "\n",
        "These kernels are usually small in spatial dimensionality, but spreads along the entirety of the depth of the input. When the data hits a convolutional layer, the layer convolves each filter across the spatial dimensionality of the input to produce a 2D activation map.\n",
        "\n",
        "One of the key differences compared to the MLP is that the neurons that the layers within the CNN are comprised of neurons organised into three dimensions, the spatial dimensionality of the input **(height, and width) and the depth**. The depth is the third dimension of an activation volume, that is the number of filters/kernels used. Unlike standard MLPs, the neurons within any given layer will only connect to a small region (receiptive field) of the layer preceding it.\n",
        "\n",
        "We are also able to define the **stride** in which we set the depth around the spatial dimensionality of the input in order to place the receptive field. For example, if we were to set a stride as 1 then we would have a heavily overlapped receptive field producing extremely large activations. Alternatively, setting the stride to a greater number will reduce the amount of overlapping and produce an output of lower spatial dimensions.\n",
        "\n",
        "**Zero-padding** is the simple process of padding the border of the input, and is an effective method to give further control as to the dimensionality of theoutput volumes. It is important to understand through the use of these tehcniques, we will in turn alter the spatial dimensionality of the convolutional layers' output. We can calculate this using the following method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "QXfkQ6w0W6w6"
      },
      "source": [
        "def calculate_conv_output(height, width, depth, kernel_size, zero_padding, stride):\n",
        "    # Receptive field size = kernel size.\n",
        "    \n",
        "    volume_size = (height*width)*depth\n",
        "    z = (zero_padding*zero_padding)\n",
        "    \n",
        "    return ((volume_size - kernel_size) + z) / stride + 1 "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VgiV_Q-W6w7"
      },
      "source": [
        "If the calculated result from this equation is not equal to a whole integer then the stride has been incorrectly set, as the neurons will be unable to fit neatly across the given input. \n",
        "\n",
        "\n",
        "See the slides for lecture10-CNNs for more information on CNN. \n",
        "Or, the standford course on CNNs https://cs231n.github.io/convolutional-networks/\n",
        "Or go through the short tutorial for the basic components in a ConvNet\n",
        "https://machinelearningmastery.com/crash-course-convolutional-neural-networks/\n",
        "\n",
        "\n",
        "## Task One: MNIST Classification\n",
        "\n",
        "Using the slides given last week, build a CNN to classify MNIST digits:\n",
        "\n",
        "Last week we reduced the data dimensionality with PCA prior to appl a feedforward neural network. This time, we'll train a network on the complete image and use a CNN, a sparsely connected network. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xgh5UHREfMDt"
      },
      "source": [
        "\n",
        "#### Just recall, in last practical, we learn how to build a simple fully connected neural network, aka Multilayer Perceptron (MLP) using dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "PvyGFH_4W6w4",
        "outputId": "297ec6d6-c57e-4876-cff7-ff56019ce678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "from keras.backend import clear_session\n",
        "\n",
        "# Good Practice Klaxon: Free your memory from previously made models.\n",
        "clear_session()\n",
        "\n",
        "# Create a new blank model\n",
        "model = Sequential()\n",
        "# Add a hidden layer of shape 2 with an input of size 4 (, denotes that we can accept variable amounts of data)\n",
        "model.add(Dense(2, input_shape=(4,)))\n",
        "# And finally, add an output layer of shape 1\n",
        "model.add(Dense(1))\n",
        "\n",
        "# Print out a summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 2)                 10        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 3         \n",
            "=================================================================\n",
            "Total params: 13\n",
            "Trainable params: 13\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uQFv4AOhu-v"
      },
      "source": [
        "Next, prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "SLjix5EeW6w7",
        "outputId": "01e3c354-61ee-4a5f-cc4e-b0f4391a4f69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# input image dimensions\n",
        "width = 28\n",
        "height = 28\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape for CNN\n",
        "X_train = X_train.reshape(X_train.shape[0], height, width, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], height, width, 1)\n",
        "input_shape = (width, height, 1)\n",
        "\n",
        "\n",
        "# Make it faster. \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "X_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyIf7LMuW6w8"
      },
      "source": [
        "Build your convolutional neural networks below (you can get some insiration from this [keras example](https://keras.io/examples/vision/mnist_convnet/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "CKcnyv0SW6w9",
        "outputId": "5b517e27-bba7-4b8c-b01d-062eed17bf57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25)) # Dropout 25% of the nodes of the previous layer during training\n",
        "model.add(Flatten())     # Flatten, and add a fully connected layer\n",
        "model.add(Dense(128, activation='relu')) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax')) # Last layer: 10 class nodes, with dropout\n",
        "model.summary()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 596,042\n",
            "Trainable params: 596,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egloE1oaW6w9"
      },
      "source": [
        "Note that we have about half a million parameters. With a strong optimizer like Adam, and a big dataset like MNIST, this shouldn't be a problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfsZ5rUSu_Eg"
      },
      "source": [
        "Also consider using GPU for accelerated computing if training is too slow using CPU only. \n",
        "\n",
        "In colab, you can easily add GPU to your runtime: just go to the top menu, click \"Runtime\"->\"Change runtime type\" -> \"Accelerater hardware\" is by default None, you can select \"GPU\" or \"TPU\" here.\n",
        "\n",
        "You can also upload the notebook to Kaggle and run it there with GPU accelorated training. \n",
        "\n",
        "TensorFlow and Keras will automatically execute on GPU if a GPU is available, so there’s nothing more you need to do after you’ve selected the GPU runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "_FwtAQaPW6w-",
        "outputId": "5bf940d9-fb05-462a-bafb-3ca4dd7cb3c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=1/6)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 36s 4ms/step - loss: 0.4561 - accuracy: 0.8574 - val_loss: 0.0615 - val_accuracy: 0.9821\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0952 - accuracy: 0.9708 - val_loss: 0.0467 - val_accuracy: 0.9859\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.0702 - accuracy: 0.9780 - val_loss: 0.0434 - val_accuracy: 0.9880\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0617 - accuracy: 0.9818 - val_loss: 0.0412 - val_accuracy: 0.9882\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0496 - accuracy: 0.9850 - val_loss: 0.0422 - val_accuracy: 0.9888\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0419 - accuracy: 0.9870 - val_loss: 0.0415 - val_accuracy: 0.9894\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.0402 - val_accuracy: 0.9901\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0311 - accuracy: 0.9896 - val_loss: 0.0398 - val_accuracy: 0.9908\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0303 - accuracy: 0.9903 - val_loss: 0.0400 - val_accuracy: 0.9894\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0299 - accuracy: 0.9902 - val_loss: 0.0393 - val_accuracy: 0.9904\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0266 - accuracy: 0.9911 - val_loss: 0.0438 - val_accuracy: 0.9905\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.0425 - val_accuracy: 0.9902\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0245 - accuracy: 0.9922 - val_loss: 0.0435 - val_accuracy: 0.9905\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0243 - accuracy: 0.9923 - val_loss: 0.0414 - val_accuracy: 0.9906\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.0401 - val_accuracy: 0.9915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f156ee9ac90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wy8noYF_1Fne"
      },
      "source": [
        "## Now evaluate the trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lLzC_zHxLcL",
        "outputId": "7f3ad7e5-cd6c-4b14-d553-497ad5dc72ea"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.030247045680880547\n",
            "Test accuracy: 0.9929999709129333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T-8tqYQ2KTZ",
        "outputId": "952d3442-6ff1-4238-9915-e9ebcc41e95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Classification report using scikit-learn \n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred) # y_pred is an 2-d array with 10 columns\n",
        "y_predc = y_pred.argmax(axis=1) #get the class labels by choosing the class with the highest output\n",
        "y_testc = y_test.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_testc, y_predc))\n",
        "print(confusion_matrix(y_true=y_testc, y_pred=y_predc))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.55239633e-16 2.25809683e-14 2.63065475e-13 ... 1.00000000e+00\n",
            "  3.07390883e-18 2.97734249e-13]\n",
            " [1.54880761e-10 3.83274568e-09 1.00000000e+00 ... 1.56422726e-14\n",
            "  1.09838625e-14 1.07271438e-19]\n",
            " [1.18689486e-15 9.99999523e-01 9.27655782e-12 ... 5.23029826e-07\n",
            "  5.03183745e-11 6.66612056e-13]\n",
            " ...\n",
            " [5.25038435e-17 1.72199809e-12 1.09858267e-15 ... 8.64090396e-12\n",
            "  8.07054645e-10 2.42530418e-09]\n",
            " [7.83052551e-14 1.89444577e-17 1.00276498e-16 ... 2.03198058e-15\n",
            "  1.22499216e-07 1.47309942e-12]\n",
            " [1.70203940e-09 1.36431986e-18 3.39773110e-12 ... 6.81060288e-21\n",
            "  1.10602395e-10 3.26676203e-16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       0.99      1.00      1.00      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.99      1.00      1.00      1010\n",
            "           4       0.99      1.00      1.00       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       1.00      0.98      0.99       958\n",
            "           7       0.99      0.99      0.99      1028\n",
            "           8       0.99      1.00      0.99       974\n",
            "           9       1.00      0.99      0.99      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "[[ 978    0    0    1    0    0    1    0    0    0]\n",
            " [   0 1134    1    0    0    0    0    0    0    0]\n",
            " [   1    1 1023    0    1    0    0    6    0    0]\n",
            " [   0    0    1 1007    0    1    0    0    1    0]\n",
            " [   0    0    0    0  979    0    1    0    0    2]\n",
            " [   1    0    1    5    0  884    1    0    0    0]\n",
            " [   6    2    0    0    2    3  942    0    3    0]\n",
            " [   0    2    4    1    0    0    0 1018    1    2]\n",
            " [   1    0    1    0    0    0    0    1  971    0]\n",
            " [   5    1    0    0    2    1    0    4    2  994]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YesYbBmzW6w-"
      },
      "source": [
        "Exercise:\n",
        "\n",
        "Try out different network architecture and hyperparameter settings, and observe the effect on performance.\n",
        "\n",
        "You can also try out the classic [LeNet architecture (LeuCun et al. 1998)](https://d2l.ai/chapter_convolutional-neural-networks/lenet.html#sec-lenet), given in the [deep learning textbook d2l.ai](https://d2l.ai/index.html), see below. \n",
        " - 2 convolutional layers uses 5×5 kernel and a sigmoid activation function. The first convolutional layer has 6 output channels, while the second has 16. Each 2×2 AvgPooling operation (stride 2). The convolutional block emits an output with shape given by (batch size, number of channel, height, width).\n",
        " - 3 dense layers, with 120, 84, and 10 outputs, respectively. Because we are still performing classification, the 10-dimensional output layer corresponds to the number of possible output classes.\n",
        "\n",
        "<a title=\"Aphex34, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\" href=\"https://d2l.ai/_images/lenet-vert.svg\"><img width=\"200\" alt=\"Typical cnn\" src=\"https://d2l.ai/_images/lenet-vert.svg\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeReJlMxUreQ",
        "outputId": "70d7b739-666b-476a-bdc0-a4557e7851e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_20 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_21 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 596,042\n",
            "Trainable params: 596,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "3125/3125 [==============================] - 10s 3ms/step - loss: 0.7026 - accuracy: 0.7458 - val_loss: 0.3254 - val_accuracy: 0.8782\n",
            "Epoch 2/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.3765 - accuracy: 0.8626 - val_loss: 0.2862 - val_accuracy: 0.8915\n",
            "Epoch 3/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.3128 - accuracy: 0.8865 - val_loss: 0.2555 - val_accuracy: 0.9051\n",
            "Epoch 4/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2893 - accuracy: 0.8975 - val_loss: 0.2571 - val_accuracy: 0.9050\n",
            "Epoch 5/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2570 - accuracy: 0.9051 - val_loss: 0.2335 - val_accuracy: 0.9132\n",
            "Epoch 6/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2382 - accuracy: 0.9135 - val_loss: 0.2368 - val_accuracy: 0.9111\n",
            "Epoch 7/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2310 - accuracy: 0.9136 - val_loss: 0.2265 - val_accuracy: 0.9155\n",
            "Epoch 8/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2141 - accuracy: 0.9204 - val_loss: 0.2253 - val_accuracy: 0.9207\n",
            "Epoch 9/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.2035 - accuracy: 0.9242 - val_loss: 0.2431 - val_accuracy: 0.9180\n",
            "Epoch 10/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1956 - accuracy: 0.9275 - val_loss: 0.2264 - val_accuracy: 0.9200\n",
            "Epoch 11/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1917 - accuracy: 0.9308 - val_loss: 0.2443 - val_accuracy: 0.9159\n",
            "Epoch 12/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1829 - accuracy: 0.9323 - val_loss: 0.2289 - val_accuracy: 0.9206\n",
            "Epoch 13/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1773 - accuracy: 0.9334 - val_loss: 0.2374 - val_accuracy: 0.9224\n",
            "Epoch 14/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1763 - accuracy: 0.9346 - val_loss: 0.2276 - val_accuracy: 0.9238\n",
            "Epoch 15/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1651 - accuracy: 0.9388 - val_loss: 0.2301 - val_accuracy: 0.9205\n",
            "Epoch 16/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1570 - accuracy: 0.9403 - val_loss: 0.2372 - val_accuracy: 0.9242\n",
            "Epoch 17/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1555 - accuracy: 0.9410 - val_loss: 0.2383 - val_accuracy: 0.9262\n",
            "Epoch 18/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1508 - accuracy: 0.9439 - val_loss: 0.2293 - val_accuracy: 0.9249\n",
            "Epoch 19/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1444 - accuracy: 0.9471 - val_loss: 0.2378 - val_accuracy: 0.9248\n",
            "Epoch 20/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1458 - accuracy: 0.9446 - val_loss: 0.2375 - val_accuracy: 0.9212\n",
            "Epoch 21/30\n",
            "3125/3125 [==============================] - 10s 3ms/step - loss: 0.1397 - accuracy: 0.9468 - val_loss: 0.2317 - val_accuracy: 0.9215\n",
            "Epoch 22/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1356 - accuracy: 0.9484 - val_loss: 0.2759 - val_accuracy: 0.9214\n",
            "Epoch 23/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1402 - accuracy: 0.9477 - val_loss: 0.2429 - val_accuracy: 0.9262\n",
            "Epoch 24/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1295 - accuracy: 0.9518 - val_loss: 0.2533 - val_accuracy: 0.9235\n",
            "Epoch 25/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1317 - accuracy: 0.9506 - val_loss: 0.2467 - val_accuracy: 0.9226\n",
            "Epoch 26/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1251 - accuracy: 0.9536 - val_loss: 0.2601 - val_accuracy: 0.9278\n",
            "Epoch 27/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1240 - accuracy: 0.9547 - val_loss: 0.2354 - val_accuracy: 0.9240\n",
            "Epoch 28/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1263 - accuracy: 0.9534 - val_loss: 0.2570 - val_accuracy: 0.9222\n",
            "Epoch 29/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1230 - accuracy: 0.9540 - val_loss: 0.2760 - val_accuracy: 0.9254\n",
            "Epoch 30/30\n",
            "3125/3125 [==============================] - 9s 3ms/step - loss: 0.1197 - accuracy: 0.9547 - val_loss: 0.2566 - val_accuracy: 0.9289\n",
            "Test loss: 0.305216908454895\n",
            "Test accuracy: 0.9229999780654907\n",
            "[[1.5061586e-20 2.4133848e-24 5.7703844e-23 ... 9.8068407e-13\n",
            "  2.3572013e-23 1.0000000e+00]\n",
            " [1.7177532e-12 1.4785444e-26 1.0000000e+00 ... 3.1001498e-38\n",
            "  2.6081231e-20 6.2616211e-36]\n",
            " [1.5960351e-21 1.0000000e+00 5.8908626e-24 ... 2.4793575e-33\n",
            "  2.5996628e-18 4.7571713e-32]\n",
            " ...\n",
            " [3.5831556e-25 1.2345758e-38 7.7961862e-30 ... 1.7715378e-26\n",
            "  1.0000000e+00 1.5255510e-30]\n",
            " [1.2740511e-17 1.0000000e+00 1.8011629e-22 ... 1.2572223e-30\n",
            "  1.2619195e-18 1.0632385e-26]\n",
            " [1.3593058e-12 7.3195862e-17 1.7634031e-15 ... 1.6117148e-03\n",
            "  2.9580629e-06 1.0811257e-04]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.86      0.88      1000\n",
            "           1       1.00      0.98      0.99      1000\n",
            "           2       0.90      0.88      0.89      1000\n",
            "           3       0.92      0.92      0.92      1000\n",
            "           4       0.86      0.90      0.88      1000\n",
            "           5       0.98      0.99      0.99      1000\n",
            "           6       0.76      0.78      0.77      1000\n",
            "           7       0.96      0.97      0.97      1000\n",
            "           8       0.99      0.98      0.98      1000\n",
            "           9       0.98      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "[[865   2  11  13   2   1 104   0   2   0]\n",
            " [  1 978   1  11   2   0   7   0   0   0]\n",
            " [ 12   0 878   7  39   0  64   0   0   0]\n",
            " [ 13   2   9 923  27   0  26   0   0   0]\n",
            " [  0   0  38  19 900   0  43   0   0   0]\n",
            " [  0   0   0   0   0 989   0   6   0   5]\n",
            " [ 71   0  39  24  79   0 780   0   7   0]\n",
            " [  0   0   0   0   0  10   0 973   0  17]\n",
            " [  3   0   2   5   1   1   5   4 978   1]\n",
            " [  0   0   0   0   0   5   1  28   0 966]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "ADgQRRjiW6w_",
        "outputId": "dcf6dcc2-9e01-4d83-8e94-7c6e19695a98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Your code\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten,AveragePooling2D\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=6, kernel_size=(5, 5), activation='sigmoid', input_shape=(28,28,1)))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Conv2D(filters=16, kernel_size=(5, 5), activation='sigmoid'))\n",
        "model.add(AveragePooling2D())\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=1/6)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# Classification report using scikit-learn \n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred) # y_pred is an 2-d array with 10 columns\n",
        "y_predc = y_pred.argmax(axis=1) #get the class labels by choosing the class with the highest output\n",
        "y_testc = y_test.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_testc, y_predc))\n",
        "print(confusion_matrix(y_true=y_testc, y_pred=y_predc))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 1.3473 - accuracy: 0.5155 - val_loss: 0.2452 - val_accuracy: 0.9217\n",
            "Epoch 2/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2379 - accuracy: 0.9264 - val_loss: 0.1603 - val_accuracy: 0.9509\n",
            "Epoch 3/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1582 - accuracy: 0.9517 - val_loss: 0.1198 - val_accuracy: 0.9639\n",
            "Epoch 4/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1115 - accuracy: 0.9645 - val_loss: 0.0908 - val_accuracy: 0.9720\n",
            "Epoch 5/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0892 - accuracy: 0.9709 - val_loss: 0.0909 - val_accuracy: 0.9736\n",
            "Epoch 6/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0732 - accuracy: 0.9770 - val_loss: 0.0811 - val_accuracy: 0.9760\n",
            "Epoch 7/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0619 - accuracy: 0.9799 - val_loss: 0.0647 - val_accuracy: 0.9796\n",
            "Epoch 8/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0529 - accuracy: 0.9837 - val_loss: 0.0596 - val_accuracy: 0.9810\n",
            "Epoch 9/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0478 - accuracy: 0.9841 - val_loss: 0.0628 - val_accuracy: 0.9822\n",
            "Epoch 10/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0412 - accuracy: 0.9865 - val_loss: 0.0617 - val_accuracy: 0.9810\n",
            "Epoch 11/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 0.0580 - val_accuracy: 0.9817\n",
            "Epoch 12/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0358 - accuracy: 0.9878 - val_loss: 0.0525 - val_accuracy: 0.9858\n",
            "Epoch 13/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0306 - accuracy: 0.9903 - val_loss: 0.0520 - val_accuracy: 0.9848\n",
            "Epoch 14/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0612 - val_accuracy: 0.9830\n",
            "Epoch 15/15\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0254 - accuracy: 0.9913 - val_loss: 0.0533 - val_accuracy: 0.9842\n",
            "Test loss: 0.04651264473795891\n",
            "Test accuracy: 0.9864000082015991\n",
            "[[9.2845722e-09 4.4788169e-07 2.4556124e-07 ... 9.9998999e-01\n",
            "  7.0673867e-09 7.8926923e-06]\n",
            " [1.9222799e-09 3.7318124e-08 9.9999976e-01 ... 1.3201962e-11\n",
            "  1.2271141e-09 1.2619092e-11]\n",
            " [6.1616809e-08 9.9988937e-01 1.6242942e-05 ... 6.8861977e-05\n",
            "  3.1876725e-06 2.3318475e-07]\n",
            " ...\n",
            " [3.3895703e-15 4.6882750e-08 4.0785552e-11 ... 5.2646580e-08\n",
            "  2.8320480e-08 1.2943839e-09]\n",
            " [7.4099349e-05 3.9847499e-09 5.7792393e-09 ... 1.4560706e-09\n",
            "  1.3565169e-04 1.8715943e-07]\n",
            " [7.2865856e-09 8.3997783e-12 1.6826393e-09 ... 3.8767409e-16\n",
            "  9.0798631e-09 9.6931341e-10]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       980\n",
            "           1       0.99      0.99      0.99      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.97      0.99      0.98      1010\n",
            "           4       0.98      0.99      0.99       982\n",
            "           5       0.99      0.97      0.98       892\n",
            "           6       0.99      0.99      0.99       958\n",
            "           7       0.98      0.99      0.98      1028\n",
            "           8       1.00      0.98      0.99       974\n",
            "           9       0.99      0.97      0.98      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n",
            "[[ 977    0    0    0    0    0    2    1    0    0]\n",
            " [   0 1129    2    1    0    0    3    0    0    0]\n",
            " [   0    0 1022    4    0    0    0    4    1    1]\n",
            " [   0    0    0 1001    0    2    0    4    0    3]\n",
            " [   0    1    0    0  976    0    2    2    0    1]\n",
            " [   2    0    0   17    0  865    2    0    1    5]\n",
            " [   5    2    1    0    2    4  944    0    0    0]\n",
            " [   0    4    4    0    0    0    0 1018    1    1]\n",
            " [   6    0    1    6    3    1    3    1  950    3]\n",
            " [   0    2    0    3   10    2    0   10    0  982]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGaWz5I2Hb7f"
      },
      "source": [
        "## Task 2 (optional): Fashion MNIST Classification\n",
        "\n",
        "Develop and evaluate a model with a more difficult MNIST dataset: [the Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist), to load the data from keras:\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5xH-eQ4H18I",
        "outputId": "c37e4458-a1a8-4365-c195-bca514604d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Your code here\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Reshape for CNN\n",
        "X_train = X_train.reshape(X_train.shape[0], height, width, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], height, width, 1)\n",
        "input_shape = (width, height, 1)\n",
        "\n",
        "\n",
        "# Make it faster. \n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "print('X_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "print(X_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten,AveragePooling2D,MaxPooling2D\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25)) # Dropout 25% of the nodes of the previous layer during training\n",
        "model.add(Flatten())     # Flatten, and add a fully connected layer\n",
        "model.add(Dense(128, activation='relu')) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax')) # Last layer: 10 class nodes, with dropout\n",
        "model.summary()\n",
        "\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_split=1/6)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# Classification report using scikit-learn \n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred) # y_pred is an 2-d array with 10 columns\n",
        "y_predc = y_pred.argmax(axis=1) #get the class labels by choosing the class with the highest output\n",
        "y_testc = y_test.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_testc, y_predc))\n",
        "print(confusion_matrix(y_true=y_testc, y_pred=y_predc))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_14 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_19 (Dense)             (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 596,042\n",
            "Trainable params: 596,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 6s 3ms/step - loss: 0.7381 - accuracy: 0.7443 - val_loss: 0.3523 - val_accuracy: 0.8702\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3752 - accuracy: 0.8655 - val_loss: 0.2824 - val_accuracy: 0.8952\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.3174 - accuracy: 0.8861 - val_loss: 0.2592 - val_accuracy: 0.9018\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2781 - accuracy: 0.8990 - val_loss: 0.2431 - val_accuracy: 0.9078\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2505 - accuracy: 0.9074 - val_loss: 0.2305 - val_accuracy: 0.9145\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2296 - accuracy: 0.9149 - val_loss: 0.2224 - val_accuracy: 0.9176\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2136 - accuracy: 0.9209 - val_loss: 0.2136 - val_accuracy: 0.9210\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2067 - accuracy: 0.9208 - val_loss: 0.2170 - val_accuracy: 0.9225\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1861 - accuracy: 0.9309 - val_loss: 0.2124 - val_accuracy: 0.9227\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1798 - accuracy: 0.9311 - val_loss: 0.2100 - val_accuracy: 0.9237\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1712 - accuracy: 0.9365 - val_loss: 0.2162 - val_accuracy: 0.9260\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1605 - accuracy: 0.9390 - val_loss: 0.2229 - val_accuracy: 0.9239\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1539 - accuracy: 0.9406 - val_loss: 0.2245 - val_accuracy: 0.9241\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1483 - accuracy: 0.9451 - val_loss: 0.2183 - val_accuracy: 0.9243\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1416 - accuracy: 0.9460 - val_loss: 0.2213 - val_accuracy: 0.9277\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1376 - accuracy: 0.9476 - val_loss: 0.2348 - val_accuracy: 0.9242\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1353 - accuracy: 0.9492 - val_loss: 0.2309 - val_accuracy: 0.9259\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1277 - accuracy: 0.9512 - val_loss: 0.2294 - val_accuracy: 0.9284\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1234 - accuracy: 0.9533 - val_loss: 0.2201 - val_accuracy: 0.9289\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1252 - accuracy: 0.9541 - val_loss: 0.2153 - val_accuracy: 0.9298\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1188 - accuracy: 0.9550 - val_loss: 0.2364 - val_accuracy: 0.9268\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1189 - accuracy: 0.9539 - val_loss: 0.2369 - val_accuracy: 0.9273\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1175 - accuracy: 0.9554 - val_loss: 0.2371 - val_accuracy: 0.9289\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1150 - accuracy: 0.9553 - val_loss: 0.2524 - val_accuracy: 0.9306\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1086 - accuracy: 0.9595 - val_loss: 0.2334 - val_accuracy: 0.9310\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1052 - accuracy: 0.9600 - val_loss: 0.2683 - val_accuracy: 0.9261\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1030 - accuracy: 0.9615 - val_loss: 0.2475 - val_accuracy: 0.9284\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1042 - accuracy: 0.9619 - val_loss: 0.2533 - val_accuracy: 0.9312\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0993 - accuracy: 0.9617 - val_loss: 0.2580 - val_accuracy: 0.9269\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0985 - accuracy: 0.9630 - val_loss: 0.2633 - val_accuracy: 0.9283\n",
            "Test loss: 0.28992047905921936\n",
            "Test accuracy: 0.9240000247955322\n",
            "[[6.8974888e-20 4.8133610e-23 5.6196082e-21 ... 1.7587093e-09\n",
            "  2.2640856e-19 1.0000000e+00]\n",
            " [5.7000880e-09 9.3545720e-25 1.0000000e+00 ... 1.5462395e-29\n",
            "  3.2268469e-14 3.0651346e-28]\n",
            " [4.9063658e-24 1.0000000e+00 5.8869922e-26 ... 9.8662666e-34\n",
            "  8.9882605e-22 2.2248856e-30]\n",
            " ...\n",
            " [5.3425313e-18 3.9259100e-25 5.6672548e-19 ... 9.2586219e-23\n",
            "  1.0000000e+00 2.0697723e-25]\n",
            " [6.2152557e-31 1.0000000e+00 3.3196804e-35 ... 0.0000000e+00\n",
            "  1.7705792e-33 0.0000000e+00]\n",
            " [2.4682972e-10 1.4599951e-11 2.9160122e-11 ... 6.1610132e-04\n",
            "  1.0243022e-07 5.2661630e-08]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.88      0.87      1000\n",
            "           1       0.99      0.98      0.99      1000\n",
            "           2       0.89      0.89      0.89      1000\n",
            "           3       0.90      0.93      0.91      1000\n",
            "           4       0.89      0.89      0.89      1000\n",
            "           5       0.99      0.98      0.99      1000\n",
            "           6       0.79      0.76      0.78      1000\n",
            "           7       0.96      0.97      0.96      1000\n",
            "           8       0.99      0.98      0.98      1000\n",
            "           9       0.97      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.92     10000\n",
            "   macro avg       0.92      0.92      0.92     10000\n",
            "weighted avg       0.92      0.92      0.92     10000\n",
            "\n",
            "[[880   1  10  18   1   0  86   0   4   0]\n",
            " [  0 983   0  12   1   0   3   0   1   0]\n",
            " [ 21   0 892  13  33   0  41   0   0   0]\n",
            " [ 13   3   9 931  18   0  26   0   0   0]\n",
            " [  0   0  38  24 892   0  45   0   1   0]\n",
            " [  0   0   0   0   0 983   0  12   0   5]\n",
            " [100   0  47  32  54   0 764   0   3   0]\n",
            " [  0   0   0   0   0   3   0 973   0  24]\n",
            " [  2   2   2   5   1   3   5   4 976   0]\n",
            " [  0   0   1   0   0   4   0  29   0 966]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbprNtNpaqsf",
        "outputId": "4e050e61-e393-41db-928e-0f9f8062e304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Your code\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Conv2D, MaxPool2D, Dropout, Flatten,AveragePooling2D\n",
        "model = Sequential()\n",
        "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25)) # Dropout 25% of the nodes of the previous layer during training\n",
        "model.add(Flatten())     # Flatten, and add a fully connected layer\n",
        "model.add(Dense(128, activation='relu')) \n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax')) # Last layer: 10 class nodes, with dropout\n",
        "model.summary()\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam()\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=64, validation_split=1/6)\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "# Classification report using scikit-learn \n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_pred) # y_pred is an 2-d array with 10 columns\n",
        "y_predc = y_pred.argmax(axis=1) #get the class labels by choosing the class with the highest output\n",
        "y_testc = y_test.argmax(axis=1)\n",
        "\n",
        "print(classification_report(y_testc, y_predc))\n",
        "print(confusion_matrix(y_true=y_testc, y_pred=y_predc))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_20 (Flatten)         (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense_51 (Dense)             (None, 128)               589952    \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 596,042\n",
            "Trainable params: 596,042\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.7359 - accuracy: 0.7416 - val_loss: 0.3347 - val_accuracy: 0.8767\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3783 - accuracy: 0.8642 - val_loss: 0.2915 - val_accuracy: 0.8923\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.3201 - accuracy: 0.8857 - val_loss: 0.2703 - val_accuracy: 0.8974\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2851 - accuracy: 0.8950 - val_loss: 0.2612 - val_accuracy: 0.9012\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2643 - accuracy: 0.9027 - val_loss: 0.2367 - val_accuracy: 0.9104\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2451 - accuracy: 0.9111 - val_loss: 0.2199 - val_accuracy: 0.9214\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2221 - accuracy: 0.9173 - val_loss: 0.2189 - val_accuracy: 0.9170\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2117 - accuracy: 0.9232 - val_loss: 0.2249 - val_accuracy: 0.9196\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1965 - accuracy: 0.9270 - val_loss: 0.2134 - val_accuracy: 0.9207\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1827 - accuracy: 0.9319 - val_loss: 0.2095 - val_accuracy: 0.9246\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1757 - accuracy: 0.9353 - val_loss: 0.2046 - val_accuracy: 0.9262\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1696 - accuracy: 0.9372 - val_loss: 0.2075 - val_accuracy: 0.9282\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1609 - accuracy: 0.9403 - val_loss: 0.2032 - val_accuracy: 0.9282\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1517 - accuracy: 0.9428 - val_loss: 0.2145 - val_accuracy: 0.9271\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.1476 - accuracy: 0.9427 - val_loss: 0.2133 - val_accuracy: 0.9267\n",
            "Test loss: 0.22779421508312225\n",
            "Test accuracy: 0.9266999959945679\n",
            "[[1.0563374e-10 1.2151169e-12 2.4456989e-10 ... 1.9703155e-05\n",
            "  1.9932934e-11 9.9998021e-01]\n",
            " [6.6379431e-07 1.2498839e-17 9.9999869e-01 ... 2.2270629e-17\n",
            "  1.6642020e-13 4.1471008e-19]\n",
            " [2.1178503e-13 1.0000000e+00 1.1291969e-13 ... 1.0318027e-22\n",
            "  1.5954045e-14 4.8710283e-23]\n",
            " ...\n",
            " [2.8877660e-09 4.8733553e-14 4.6644615e-11 ... 1.6680949e-12\n",
            "  1.0000000e+00 9.5083568e-14]\n",
            " [2.0862821e-12 1.0000000e+00 1.2473439e-14 ... 2.4896666e-20\n",
            "  4.6686868e-16 1.6167548e-19]\n",
            " [1.2399120e-07 2.3839911e-10 3.3923973e-07 ... 1.4407979e-02\n",
            "  1.8655356e-06 3.4518784e-05]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.90      0.88      1000\n",
            "           1       1.00      0.98      0.99      1000\n",
            "           2       0.90      0.88      0.89      1000\n",
            "           3       0.92      0.93      0.92      1000\n",
            "           4       0.87      0.90      0.88      1000\n",
            "           5       0.98      0.99      0.99      1000\n",
            "           6       0.80      0.77      0.78      1000\n",
            "           7       0.97      0.97      0.97      1000\n",
            "           8       0.99      0.98      0.99      1000\n",
            "           9       0.98      0.97      0.97      1000\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.93      0.93      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n",
            "[[898   0  12  12   3   1  70   0   4   0]\n",
            " [  2 979   0  13   1   0   4   0   1   0]\n",
            " [ 19   0 875   7  49   0  50   0   0   0]\n",
            " [ 14   1   9 931  24   0  20   0   1   0]\n",
            " [  1   0  29  18 902   0  49   0   1   0]\n",
            " [  0   0   0   0   0 987   0   8   0   5]\n",
            " [ 96   0  41  30  60   0 769   0   4   0]\n",
            " [  0   0   0   0   0   7   0 975   0  18]\n",
            " [  3   1   2   3   1   1   4   2 983   0]\n",
            " [  0   0   0   0   0   7   0  24   1 968]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}